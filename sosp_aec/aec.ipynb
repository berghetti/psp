{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "# %matplotlib notebook\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "# %matplotlib notebook\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "# plt.style.use('seaborn')\n",
    "# sns.set(rc={'figure.facecolor':'white'})\n",
    "# sns.set_style(\n",
    "#     'white', \n",
    "#     {\n",
    "#         'axes.spines.left': True,\n",
    "#         'axes.spines.bottom': True,\n",
    "#         'axes.spines.right': False,\n",
    "#         'axes.spines.top': False\n",
    "#     }\n",
    "# )\n",
    "# sns.despine()\n",
    "\n",
    "fd = {'family': 'normal', 'weight': 'bold', 'size': 9}\n",
    "matplotlib.rc('font', **fd)\n",
    "matplotlib.rcParams['lines.markersize'] = 3\n",
    "\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "from matplotlib import lines\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.options.display.float_format = '{:.9f}'.format\n",
    "\n",
    "from loader import *\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "linestyles= [\n",
    "    ('dotted',                (0, (1, 1))),\n",
    "    ('dashed',                (0, (5, 5))),\n",
    "    ('dashdotted',            (0, (3, 5, 1, 5))),\n",
    "    ('dashdotdotted',         (0, (3, 5, 1, 5, 1, 5))),\n",
    "\n",
    "    ('loosely dotted',        (0, (1, 10))),\n",
    "    ('loosely dashed',        (0, (5, 10))),\n",
    "    ('loosely dashdotted',    (0, (3, 10, 1, 10))),\n",
    "    ('loosely dashdotdotted', (0, (3, 10, 1, 10, 1, 10))),\n",
    "\n",
    "    ('densely dotted',        (0, (1, 1))),\n",
    "    ('densely dashed',        (0, (5, 1))),\n",
    "    ('densely dashdotted',    (0, (3, 1, 1, 1))),\n",
    "    ('densely dashdotdotted', (0, (3, 1, 1, 1, 1, 1)))\n",
    "]\n",
    "ts_pal = {\"SHORT\": \"C0\", \"LONG\": \"C1\", \"PAGE\":\"C0\",\"REGEX\":\"C1\", 'NewOrder': 'C0', 'Payment': 'C1', 'Delivery': 'C2', 'StockLevel': 'C3', 'OrderStatus': 'C4', 'UNKNOWN': 'C1'}\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "def plot_setups_traces(exps, data_types=[], show_ts=False, pctl=1, reset_figure=True, app='REST', **kwargs):\n",
    "    req_types = apps[app]\n",
    "    \n",
    "    if reset_figure:\n",
    "        plt.close('all')\n",
    "    if (len(data_types) == 0):\n",
    "        data_types = ['client-end-to-end']\n",
    "\n",
    "    setups = prepare_traces(exps, data_types, pctl=pctl, **kwargs)\n",
    "\n",
    "    if show_ts:\n",
    "        ncols = len(setups)\n",
    "    else:\n",
    "        ncols = len(req_types)\n",
    "\n",
    "    for i, t in enumerate(data_types):\n",
    "        # Instantiate the figure\n",
    "        plt.figure(i+1, figsize=(10, 10))\n",
    "        if show_ts:\n",
    "            sy=True\n",
    "        else:\n",
    "            sy=False\n",
    "        fig, axs = plt.subplots(1, ncols, squeeze=False, sharey=sy, sharex=False, num=i+1)   \n",
    "        for j, setup in enumerate(setups.keys()):\n",
    "            setups[setup][t].VALUE /= 1000\n",
    "            if show_ts:\n",
    "                c_index = j % ncols\n",
    "                sns.scatterplot(x=setups[setup][t].TIME, y='VALUE', data=setups[setup][t], hue=\"REQ_TYPE\", ax=axs[0][c_index], label=setup, palette=ts_pal)#, style=\"REQ_TYPE\")\n",
    "                axs[0][c_index].set(xlabel='Time', ylabel='latency (us)')\n",
    "            else:\n",
    "                if pctl != 1:\n",
    "                    base = pctl\n",
    "                else:\n",
    "                    base = 0\n",
    "                setups[setup][t].sort_values(by=['VALUE'], inplace=True)\n",
    "                \n",
    "                for col, rtype in enumerate(req_types):\n",
    "                    type_df = setups[setup][t][setups[setup][t].REQ_TYPE == rtype]\n",
    "                    y = np.linspace(base, 1, len(type_df.VALUE))\n",
    "                    x = np.sort(type_df.VALUE)\n",
    "                    print('[{}: {}] mean: {}, median: {}, p99: {}'.format(\n",
    "                        setup, rtype,\n",
    "                        int(type_df.VALUE.mean()),\n",
    "                        int(type_df.VALUE.median()),\n",
    "                        int(type_df.VALUE.quantile(.99))\n",
    "                    ))\n",
    "                    axs[0][col].axhline(.99, color='grey', linestyle='dotted')\n",
    "                    axs[0][col].xaxis.set_major_formatter(ScalarFormatter())\n",
    "                    axs[0][col].plot(x, y, label=setup)\n",
    "                    axs[0][col].set(xlabel='latency (us)', ylabel='% requests')\n",
    "                    axs[0][col].set_title(rtype)\n",
    "\n",
    "            fig.suptitle('{}'.format(t))\n",
    "            axs[0][0].legend()\n",
    "\n",
    "alph = ['(a)', '(b)', '(c)', '(d)', '(e)', '(f)']\n",
    "def plot_p99s(distros, app=\"REST\", value='p99', use_ylim=True, close_all=True, add_shen=False, **kwargs):\n",
    "    if close_all:\n",
    "        plt.close('all')\n",
    "    colors = list(mcolors.TABLEAU_COLORS.keys())[:len(policies)]\n",
    "    colors[6] = 'tab:gray'\n",
    "    markers = ['D', '^', 'o', 'v', '<', '>', 'p', 'h', 'X', '+'][:len(policies)]\n",
    "    c = {pol: color for pol, color in zip(policies.values(), colors)}\n",
    "#     l = {pol: lstyle for pol, (_, lstyle) in zip(policies.values(), linestyles)}\n",
    "    l = {pol: 'solid' for pol in policies.values()}\n",
    "    m = {pol: marker for pol, marker in zip(policies.values(), markers)}\n",
    "\n",
    "    req_types = apps[app]\n",
    "    if app == 'SILO' or app == 'TPCC' or app == 'ROCKSDB':\n",
    "        top = 250\n",
    "        sy=True\n",
    "        left = 0\n",
    "    elif app == 'REST':\n",
    "        sy = False\n",
    "        left = 25\n",
    "    elif app == 'MB':\n",
    "        sy=False\n",
    "        left = 0 # FIXME: input smallest offered load\n",
    "    \n",
    "    nrows = len(distros)\n",
    "    ncols = len(req_types) + 1\n",
    "    ncols = 2\n",
    "    fig, axes = plt.subplots(nrows, ncols, squeeze=False, sharey=False, sharex=False, figsize=(15,3))\n",
    "    row_labels = []\n",
    "    for row, dist in enumerate(distros):\n",
    "        psp_df_all, psp_df_typed = prepare_pctl_data(req_types, exp_file=dist, **kwargs)\n",
    "        if add_shen:\n",
    "            shen_df_all, shen_df_typed = parse_shenango_data('/home/maxdml/experiments/shenango.3', dist)\n",
    "            if not shen_df_all.empty:\n",
    "                shen_df_all.achieved /=1000\n",
    "                shen_df_all.offered /= 1000\n",
    "                shen_df_typed.achieved /=1000\n",
    "                shen_df_typed.offered /= 1000\n",
    "                # Make shenango's experiments with drops infinite latency # FIXME: not really fair because we don't tolerate anything like we do with psp\n",
    "                shen_df_typed[value] = shen_df_typed.apply(lambda x: sys.maxsize if x.achieved < x.offered else x[value], axis=1)\n",
    "                shen_df_all[value] = shen_df_all.apply(lambda x: sys.maxsize if x.achieved < x.offered else x[value], axis=1)\n",
    "\n",
    "            df = pd.concat([psp_df_all, shen_df_all]).groupby(['achieved', 'policy', 'type']).min().reset_index(drop=False)\n",
    "            typed_df = pd.concat([psp_df_typed, shen_df_typed]).groupby(['achieved', 'policy', 'type']).min().reset_index(drop=False)\n",
    "        else:\n",
    "            df = psp_df_all.groupby(['achieved', 'policy', 'type']).min().reset_index(drop=False)\n",
    "            typed_df = psp_df_typed.groupby(['achieved', 'policy', 'type']).min().reset_index(drop=False)\n",
    "\n",
    "#         print(df[df.achieved  < df.offered][['offered', 'achieved', 'policy']])\n",
    "        for pol_inter, pol in policies.items():\n",
    "            typed_d = typed_df[typed_df.policy == pol].sort_values(by=['load'])\n",
    "#             import pdb; pdb.set_trace()\n",
    "            d = df[df.policy == pol].sort_values(by=['load'])\n",
    "            if d.empty or typed_d.empty:\n",
    "                print(f\"{pol} empty\")\n",
    "                continue\n",
    "\n",
    "#             print(f'using {m[pol]}')\n",
    "            runs = typed_d.run_number.unique()\n",
    "            if len(runs) > 1:\n",
    "                for run in runs:\n",
    "                    dd = d[d.run_number == run]\n",
    "                    line, = axes[row][0].plot(dd.offered, dd[value+'_slowdown'], marker=m[pol], linestyle=l[pol])#, color=c[pol])\n",
    "                    line.set_label(f'{pol_names[pol]}-{run}')\n",
    "                if use_ylim:\n",
    "                    axes[row][0].set_ylim(bottom=-5, top=workloads[dist]['UNKNOWN']['YLIM'])\n",
    "                axes[row][0].set_xlim(left=left, right=workloads[dist]['max_load']/1000)\n",
    "                axes[row][0].grid(b=True, axis='y', linestyle='-', linewidth=1)\n",
    "                axes[row][0].set_title('Overall', fd)\n",
    "                axes[row][0].set_ylabel(f'p99.9 slowdown', fd)\n",
    "                \n",
    "                for run in runs:\n",
    "                    for i, rtype in enumerate(req_types):\n",
    "#                         if rtype == 'LONG':\n",
    "#                             value = 'p99'\n",
    "                        col = i + 1\n",
    "                        type_df = typed_d[(typed_d.type == rtype) & (typed_d.run_number == run)]\n",
    "                        line, = axes[row][col].plot(type_df.offered, type_df[value], marker=m[pol], linestyle=l[pol])#, color=c[pol])\n",
    "                        if use_ylim:\n",
    "                            axes[row][col].set_ylim(bottom=-5, top=workloads[dist][rtype]['YLIM'])\n",
    "                        axes[row][col].set_xlim(left=left, right=workloads[dist]['max_load']/1000)\n",
    "                        axes[row][col].grid(b=True, axis='y', linestyle='-', linewidth=1)\n",
    "                        if col == 1:\n",
    "                             axes[row][col].set_ylabel(f'p99.9 latency (us)', fd)\n",
    "                        axes[row][col].set_title(f'{rtype}', fd)\n",
    "            else:\n",
    "                line, = axes[row][0].plot(d.offered, d[value+'_slowdown'], marker=m[pol], linestyle=l[pol], color=c[pol])\n",
    "                line.set_label(pol_names[pol] + \" (\" + system_pol[pol_inter] + ')')\n",
    "    #             axes[row][0].set_yscale('log')\n",
    "                if use_ylim:\n",
    "                    axes[row][0].set_ylim(bottom=-5, top=workloads[dist]['UNKNOWN']['YLIM'])\n",
    "#                     axes[row][0].set_ylim(bottom=-5, top=3500)\n",
    "                axes[row][0].set_xlim(left=left, right=workloads[dist]['max_load']/1000)\n",
    "#                 axes[row][0].set_xlim(left=left, right=4000)\n",
    "                axes[row][0].grid(b=True, axis='y', linestyle='-', linewidth=1)\n",
    "                axes[row][0].set_title('Overall', fd)\n",
    "                axes[row][0].set_ylabel(f'p99.9 slowdown', fd)\n",
    "\n",
    "#                 for i, rtype in enumerate(req_types):\n",
    "                for i, rtype in enumerate(['LONG']):\n",
    "                    col = i + 1\n",
    "                    type_df = typed_d[typed_d.type == rtype]\n",
    "                    line, = axes[row][col].plot(type_df.offered, type_df[value], marker=m[pol], linestyle=l[pol], color=c[pol])\n",
    "    #                 line.set_label(pol + \"\\n(\" + system_pol[pol_inter] + ')')\n",
    "    #                 axes[row][col].set_yscale('log')\n",
    "    #                 axes[row][col].yaxis.get_major_formatter().set_scientific(False)\n",
    "                    if use_ylim:\n",
    "#                         axes[row][col].set_ylim(bottom=-5, top=3500)\n",
    "                        axes[row][col].set_ylim(bottom=-5, top=workloads[dist][rtype]['YLIM'])\n",
    "                    axes[row][col].set_xlim(left=left, right=workloads[dist]['max_load']/1000)\n",
    "#                     axes[row][0].set_xlim(left=left, right=4000)\n",
    "\n",
    "                    axes[row][col].grid(b=True, axis='y', linestyle='-', linewidth=1)\n",
    "                    if col == 1:\n",
    "                         axes[row][col].set_ylabel(f'p99.9 latency (us)', fd)\n",
    "\n",
    "                    # Here add second axis with achieved. Plot offered\n",
    "    #                 goodput_ax = axes[row][col].twinx()\n",
    "    #                 goodput_ax.plot(type_df.offered, type_df.achieved, alpha=0.001)\n",
    "\n",
    "    #                 axes[row][col].set_title(f'{alph[i+1]} {rtype}', fd)\n",
    "                    axes[row][col].set_title(f'{rtype}', fd)\n",
    "        \n",
    "        fig.text(0.5, 0.02, 'Throughput (kRPS)', fd, ha='center', va='center')\n",
    "#         fig.text(0.08, 0.5, f'{value} (us)', fd, ha='center', va='center', rotation='vertical')\n",
    "#         row_labels.append(workloads[dist]['name'])\n",
    "    \n",
    "    pad = 5\n",
    "    for ax, col in zip(axes[:,0], row_labels):\n",
    "        ax.annotate(col, xy=(0,.5), xytext=(-ax.yaxis.labelpad - pad, 0),\n",
    "                    xycoords=ax.yaxis.label, textcoords='offset points',\n",
    "                    size='large', ha='right', va='center', rotation=90)\n",
    "                    \n",
    "#     plt.xlabel('Goodput (kRPS)', fontsize=18)\n",
    "#     plt.ylabel('p99 latency (us)', fontsize=16)\n",
    "\n",
    "#     page_mean = df['PAGE mean (ns)'].mean()\n",
    "#     yticks = axes[0][0].get_yticks()\n",
    "#     yticks_labels = ['{}'.format(tick) for tick in yticks]\n",
    "# #     yticks_labels = ['{} / {:.2f}'.format(tick, tick/page_mean) for tick in yticks]\n",
    "#     axes[0][0].set_yticklabels(yticks_labels)\n",
    "#     axes[0][0].set_ylabel('p99 latency (ns) / factor of mean latency');\n",
    "    \n",
    "                \n",
    "#     axes[0][0].legend()\n",
    "#     for row in range(nrows):\n",
    "    if app == 'SILO' or app == 'TPCC':\n",
    "        bbox = (1,1.15,5.5,0)\n",
    "    else:\n",
    "#         bbox = (-.5,1.4,2,0.2) # all 4 workloads\n",
    "#         bbox = (0,1.2,1,0) # only slowdown\n",
    "        bbox= (0.125,1.2,2,0) # slowdown and longs\n",
    "#         bbox =(.75, 1.2, 2, 0) # slowdown and both types\n",
    "    leg = axes[0][0].legend(loc='upper center', bbox_to_anchor=bbox, ncol=4, fancybox=True, shadow=True, frameon=True, mode='expand', borderaxespad=-1)\n",
    "    for legobj in leg.legendHandles:\n",
    "        legobj.set_linewidth(2.0)\n",
    "#     plt.rcParams['legend.title_fontsize'] = 'xx-small'\n",
    "#     plt.subplots_adjust(left=0.05, bottom=None, right=0.95, top=None, wspace=0.3, hspace=0)\n",
    "    plt.subplots_adjust(left=None, bottom=None, right=None, top=.8, wspace=None, hspace=None)\n",
    "#     fig.set_canvas(plt.gcf().canvas)\n",
    "    plt.savefig(f'/home/maxdml/experiments/{distros[0]}.pdf', format='pdf')\n",
    "#     gs1 = gridspec.GridSpec(23, 8)\n",
    "#     gs1.update(wspace=0.025, hspace=0.05) # set the spacing between axes.\n",
    "#     set_size(20,5)\n",
    "#     fig.tight_layout()\n",
    "    \n",
    "def set_size(w,h, ax=None):\n",
    "    \"\"\" w, h: width, height in inches \"\"\"\n",
    "    if not ax: ax=plt.gca()\n",
    "    l = ax.figure.subplotpars.left\n",
    "    r = ax.figure.subplotpars.right\n",
    "    t = ax.figure.subplotpars.top\n",
    "    b = ax.figure.subplotpars.bottom\n",
    "    figw = float(w)/(r-l)\n",
    "    figh = float(h)/(t-b)\n",
    "    ax.figure.set_size_inches(figw, figh)\n",
    "    \n",
    "    \n",
    "def plot_wcc(distro, value='p99', **kwargs):\n",
    "    req_types = apps['MB']\n",
    "    df, typed_df = prepare_pctl_data(req_types, exp_file=distro, **kwargs)\n",
    "#     print(data)\n",
    "    \n",
    "    # 1 subplot\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6.5,3.25))\n",
    "    ax.set_ylabel(f'{value} slowdown', fd)\n",
    "    ax.set_xlabel('Number of reserved workers', fd)\n",
    "    ax.grid(b=True, axis='y', linestyle='-', linewidth=1)\n",
    "    for pol_inter, pol in policies.items():\n",
    "        typed_d = typed_df[typed_df.policy == pol].sort_values(by=['reserved'])\n",
    "        typed_d = typed_d[typed_d.type == 'SHORT']\n",
    "        d = df[df.policy == pol].sort_values(by=['load'])\n",
    "        if d.empty or typed_d.empty:\n",
    "            print(f\"{pol} empty\")\n",
    "            continue\n",
    "#         print(typed_d)\n",
    "\n",
    "        # Plot DARC with varying reserved cores\n",
    "        line, = ax.plot(d.reserved, d[value+'_slowdown'], marker='^', linestyle='solid', color='green', label='DARC-static')\n",
    "        \n",
    "        # Plot DARC algorithm selection\n",
    "        ax.axvline(x=2, color='green', linestyle='dashed', label='DARC')\n",
    "        \n",
    "    # Plot straight lines for cFCFS and FP\n",
    "    # SBIM2: 3542 in shenango, 3174 in psp\n",
    "    # DISP2: 110\n",
    "    ax.plot(np.arange(0,14), [3542]*14, linestyle='dashed', color='black', label='c-FCFS')\n",
    "#     ax.legend(loc=\"upper right\", ncol=3,  bbox_to_anchor=(-.1, 1.375, 1, 0))\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylim(top=1e4)\n",
    "#     plt.title('(a)', fd)\n",
    "    fig.tight_layout()\n",
    "    \n",
    "def plot_tp(exps, hue=False):\n",
    "    plt.close('all')\n",
    "    fig, axes = plt.subplots(len(exps), 1, squeeze=False, num=1)\n",
    "    for i, exp in enumerate(exps):\n",
    "        df = read_client_tp(exp)\n",
    "        df.N *= 1000\n",
    "#         print('{} overall max throughput: {}'.format(exp, int(df.groupby(['W_ID', 'TYPE']).N.max())))\n",
    "        print('{} overall average throughput: {}'.format(exp, int(df.groupby(['W_ID', 'TYPE']).N.mean().sum())))\n",
    "        print('{} average {} throughput: {}, average {} throughput: {}'.format(\n",
    "            exp,\n",
    "            'SHORT', int(df[df.TYPE == 'SHORT'].groupby('W_ID').N.mean().sum()),\n",
    "            'LONG', int(df[df.TYPE == 'LONG'].groupby('W_ID').N.mean().sum()),\n",
    "        ))\n",
    "        df.TIME -= min(df.TIME)\n",
    "        if hue:\n",
    "            sns.lineplot(x='TIME', y='N', data=df, hue='TYPE', ax=axes[i][0], ci=None)\n",
    "        else:\n",
    "            sns.lineplot(x='TIME', y='N', data=df, ax=axes[i][0], ci=None)\n",
    "#         axes[i][0].set_ylim(ymin=0)\n",
    "    \n",
    "def plot_allocs(exp):\n",
    "    plt.close('all')\n",
    "    fname = os.path.join('/home/maxdml/experiments', exp, 'server', 'windows');\n",
    "    with open(fname, 'r') as f:\n",
    "        df = pd.read_csv(fname, delimiter='\\t')\n",
    "    df.TIME -= min(df.TIME)\n",
    "    df.TIME /= 1e9\n",
    "    fig, axes = plt.subplots(3, 1, squeeze=False)\n",
    "    sns.scatterplot(x='TIME', y='RES', data=df, hue=\"GID\", ax=axes[0][0], s=16)\n",
    "#     for gid in df.GID.unique():\n",
    "#         gdf = df[df.GID == gid]\n",
    "#         gdf.TIME -= min(gdf.TIME)\n",
    "#         sns.scatterplot(x='TIME', y='RES', data=gdf, ax=axes[0][0], s=16, label=gid)\n",
    "    time_series = df[df.GID == 0].reset_index()\n",
    "    time_series = time_series.TIME - time_series.TIME.shift()\n",
    "    print(time_series.describe())\n",
    "    sns.scatterplot(data=time_series, ax=axes[1][0], hue=\"GID\", s=16, label=0)\n",
    "    axes[1][0].get_legend().remove()\n",
    "    sns.scatterplot(x='TIME', y='COUNT', data=df, hue='GID', ax=axes[2][0] ,color='black')\n",
    "    axes[2][0].get_legend().remove()\n",
    "#     axes[2][0].set_ylim(top=100000)typed_lat_df\n",
    "\n",
    "#TODO: setup the right color/markers for each exp\n",
    "#TODO: check that schedule is the same across experiments\n",
    "def plot_agg_p99_over_time(exps, app='MB', debug=False, **kwargs):\n",
    "    if not isinstance(exps, list):\n",
    "        exps = [exps]\n",
    "    req_types = apps[app] # Assume the schedule has the same types\n",
    "    req_names = {'SHORT': 'A', 'LONG': 'B'}\n",
    "    \n",
    "    style = {}\n",
    "#     colors = list(mcolors.TABLEAU_COLORS.keys())\n",
    "#     colors = ['#377eb8', '#ff7f00', '#4daf4a',\n",
    "#                   '#f781bf', '#a65628', '#984ea3',\n",
    "#                   '#999999', '#e41a1c', '#dede00']\n",
    "    colors = ['black'] * len(exps) * 2\n",
    "    markers = ['p', '^', 'o', 'v', '<', '>', 'x', 'h', 'X', '+']\n",
    "    lsizes = {'c-FCFS': .25, \"DARC\": 2.5}\n",
    "    msizes = {'c-FCFS': 4, \"DARC\": 7}\n",
    "    for exp in exps:\n",
    "        pol = policies[exp.split('_')[0]]\n",
    "        if pol == 'DYN-RESA':\n",
    "            pol = 'DARC'\n",
    "        for rtype in req_types:\n",
    "            name = req_names[rtype] + '_' + pol if len(exps) > 1 else req_names[rtype]\n",
    "            style[name] = {}\n",
    "            style[name]['color'] = colors[len(style.keys()) - 1]\n",
    "            style[name]['marker'] = markers[len(style.keys()) - 1]\n",
    "            style[name]['line'] = linestyles[len(style.keys()) - 1]\n",
    "    c = {t: color for t, color in zip(req_types, colors)}\n",
    "    background_filled = False\n",
    "    # Plot each req type\n",
    "    plt.close('all')\n",
    "    t0 =  time.time()\n",
    "    setups = prepare_traces(exps, ['client-end-to-end'], pctl=1, clients=[0,1,2,3,4,5], seconds=False, get_schedule_data=True, **kwargs)\n",
    "    nrows = 2\n",
    "    if debug:\n",
    "        nrows += 2\n",
    "    fig, axes = plt.subplots(nrows, 1, squeeze=False, num=1, sharex=True, figsize=(12,5))\n",
    "    max_y = 0\n",
    "    for e, exp in enumerate(exps):\n",
    "        pol = policies[exp.split('_')[0]]\n",
    "        if pol == 'DYN-RESA':\n",
    "            pol = 'DARC'\n",
    "        df, throughput_df, schedule, alloc = setups[exp]['bins'], setups[exp]['tp'], setups[exp]['schedule'], setups[exp]['alloc']\n",
    "        for i, req_type in enumerate(req_types):\n",
    "            typed_lat_df = df[df.REQ_TYPE == req_type]\n",
    "    #         print(typed_lat_df.VALUE.describe([.25, .5, .75, .9, .99, .999, .9999]))\n",
    "            # Groupby bins and get p99.9\n",
    "            total_p999 = typed_lat_df.VALUE.quantile(.999) / 1000\n",
    "    #         total_p99 = typed_lat_df.VALUE.quantile(.99) / 1000\n",
    "    #         total_p90 = typed_lat_df.VALUE.quantile(.9) / 1000\n",
    "    #         total_p50 = typed_lat_df.VALUE.quantile(.5) / 1000\n",
    "    #         import pdb; pdb.set_trace()\n",
    "            lat_df = typed_lat_df.groupby(['time_bin'])[['VALUE', 'SCHED_ID']].quantile(0.999).reset_index() # This is a shitty/buggy way to keep the sched_id\n",
    "            lat_df.VALUE /= 1000\n",
    "            if max(lat_df.VALUE) > max_y:\n",
    "                max_y = max(lat_df.VALUE) + max(lat_df.VALUE)*.05\n",
    "            axes[0][0].hlines(y=total_p999, xmin=0, xmax=max(lat_df.index/1e1), linestyles=':', color=c[req_type], label=req_names[req_type] +'_p999')\n",
    "    #         axes[0][0].hlines(y=total_p99, xmin=0, xmax=max(lat_df.index/1e1), linestyles='-.', color=c[req_type], label=req_names[req_type] +'_p99')\n",
    "    #         axes[0][0].hlines(y=total_p90, xmin=0, xmax=max(lat_df.index/1e1), linestyles='--', color=c[req_type], label=req_names[req_type] +'_p90')\n",
    "    #         axes[0][0].hlines(y=total_p50, xmin=0, xmax=max(lat_df.index/1e1), linestyles='-', color=c[req_type], label=req_names[req_type] +'_p50')\n",
    "            label = req_names[req_type] + '_' + pol if len(exps) > 1 else req_names[req_type]\n",
    "            if debug:\n",
    "                sns.lineplot(\n",
    "                    x=lat_df.index / 1e1, y='VALUE', data=lat_df, ax=axes[0][0], hue=\"SCHED_ID\",\n",
    "                    color=style[label]['color'], marker=style[label]['marker'],  markersize=7,\n",
    "                    style=\"SCHED_ID\", label=label\n",
    "                )\n",
    "#                 typed_tp_df = throughput_df[throughput_df.TYPE == req_type]\n",
    "#                 sns.lineplot(x=typed_tp_df.TIME/1e9, y='N', data=typed_tp_df, ax=axes[2][0], color=c[req_type])\n",
    "#                 axes[2][0].set_ylabel(f'Throughput (Krps)', fd)\n",
    "            else:\n",
    "                sns.lineplot(\n",
    "                    x=lat_df.index / 1e1, y='VALUE', data=lat_df, ax=axes[0][0],\n",
    "                    color=style[label]['color'], marker=style[label]['marker'], linewidth=lsizes[pol], markersize=msizes[pol],\n",
    "                    label=label\n",
    "                )\n",
    "        axes[0][0].set_ylabel(f'p99.9 latency (us)', fd)\n",
    "        axes[0][0].set_xlabel('')\n",
    "        \n",
    "        # Add a row for core allocation\n",
    "        if not alloc.empty:\n",
    "            pal_start = e*len(req_types)\n",
    "            pal_end = e*len(req_types) + len(alloc.GID.unique())\n",
    "            # Core allocation\n",
    "            sns.lineplot(x='START', y='RES', data=alloc, hue=\"GID\", ax=axes[1][0], palette=colors[pal_start:pal_end], markers=['p', '^'], style='GID', dashes=False, markersize=9)\n",
    "            axes[1][0].set_xlabel('')\n",
    "            axes[1][0].set_ylabel(f'Core allocation', fd)\n",
    "            axes[1][0].get_legend().remove()\n",
    "            if debug:\n",
    "                # Qlen at allocation time\n",
    "                sns.lineplot(x='START', y='QLEN', data=alloc, hue=\"GID\", ax=axes[3][0], palette=list(mcolors.TABLEAU_COLORS.keys())[pal_start:pal_end], markers=['p','^'], markersize=7)\n",
    "                axes[3][0].set_xlabel('')\n",
    "                axes[3][0].set_ylabel(f'Qlen at allocation', fd)\n",
    "                axes[3][0].get_legend().remove()\n",
    "\n",
    "    # Fill background // Assume same schedule across provided experiments\n",
    "#     offset = 0\n",
    "    start_times_df = df.groupby('SCHED_ID').time_bin.min()\n",
    "    start_times = np.insert(start_times_df[1:].apply(lambda x: x.left).values, 0, 0)\n",
    "    end_times = np.append(start_times[1:], max(df.TIME))\n",
    "    schedule = setups[exps[0]]['schedule']\n",
    "    for w, workload in enumerate(schedule):      \n",
    "#         start_time = offset\n",
    "#         end_time = (start_time + workload['duration'])\n",
    "#         offset += workload['duration']\n",
    "        start = start_times[w] / 1e9\n",
    "        end = end_times[w] / 1e9\n",
    "        print(f'filling between {start} and {end}')\n",
    "        for n in range(nrows):\n",
    "            axes[n][0].axvspan(start, end, alpha=.1, color=list(mcolors.TABLEAU_COLORS.keys())[w%2])# color=colors[w%2])\n",
    "            axes[n][0].axvline(x=start, linewidth=1, color='black', dashes=(5, 2, 1, 2))\n",
    "        wl = gen_wl_dsc(workload, req_names)\n",
    "        axes[0][0].text(\n",
    "            start + .5, max_y, wl, style='italic', fontsize=12,\n",
    "#             height=None,\n",
    "            bbox={'facecolor': 'green', 'alpha': 0.5, 'boxstyle': 'round'}#, 'pad': -1}\n",
    "        )\n",
    "                \n",
    "    axes[-1][0].set_xlabel(f'Sending time (seconds)', fd)\n",
    "    axes[0][0].set_ylim(bottom=-5, top=1000)\n",
    "    \n",
    "    if debug:\n",
    "#         handles, labels = axes[0][0].get_legend_handles_labels()\n",
    "#         axes[0][0].legend(handles=[], labels=[])\n",
    "        axes[0][0].get_legend().remove()\n",
    "    \n",
    "\n",
    "    #     h, _ = axes[0][0].get_legend_handles_labels()\n",
    "        fig.legend(loc='right')#, handles=h)\n",
    "    #     print(axes[0][0].lines.get_legend_handles_labels())\n",
    "    print(f'plotted data in {time.time() - t0}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d69fb25883654a859f7feca1df74256d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.close('all')\n",
    "lat_df = (cache['DYN-RESA_0.80_sched4_14.38']['alloc'].END - cache['DYN-RESA_0.80_sched4_14.38']['alloc'].START).values[:-2]\n",
    "y = np.linspace(0, 1, len(lat_df))\n",
    "x = np.sort(lat_df) / 1e3\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d9deb5a7d3042c7948504a5a2f8e34e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filling between 0.0 and 5.11282762742\n",
      "filling between 5.11282762742 and 10.325906776947\n",
      "filling between 10.325906776947 and 15.538985926473\n",
      "filling between 15.538985926473 and 20.752065076\n",
      "plotted data in 34.255152463912964\n"
     ]
    }
   ],
   "source": [
    "%pdb on\n",
    "exps = ['DYN-RESA_0.80_sched4_14.40']\n",
    "plot_agg_p99_over_time(exps, reset_cache=False, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3414fe612cd7473992a83ea4a1c9ae26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d-FCFS empty\n",
      "c-FCFS empty\n",
      "ARS-FP empty\n",
      "EDF empty\n",
      "c-PRE-SQ empty\n"
     ]
    }
   ],
   "source": [
    "%pdb off\n",
    "# distros = ['DISP2', 'SBIM2']\n",
    "distros = ['DISP2']\n",
    "plot_p99s(distros, app='MB', reset_cache=False, use_ylim=True, clients=[0,1,2,3,4,5], value=\"p99.9\", close_all=True, remove_drops=True, add_shen=True)\n",
    "\n",
    "#     * DARC-110: dynamic with ceiling\n",
    "#     * DARC-118: dynamic with ceiling + no std::sort\n",
    "#     * DARC-119: dynamic with ceiling + only 5us updates\n",
    "#     * DARC-106 : oracle with ceiling\n",
    "\n",
    "#     * DARC-111: dynamic with rounding // & 97 on faster machine // & 125\n",
    "#     * DARC-142: dynamic with rounding + only 5us updates % 10k samples // & 126\n",
    "#     * DARC-103: oracle with rounding // & 94 on faster machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "701188660e934828a78f461cdb9994f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d-FCFS empty\n",
      "c-FCFS empty\n",
      "ARS-FP empty\n",
      "EDF empty\n",
      "c-PRE-MQ empty\n"
     ]
    }
   ],
   "source": [
    "%pdb off\n",
    "# distros = ['DISP2', 'SBIM2']\n",
    "distros = ['SBIM2']\n",
    "plot_p99s(distros, app='MB', reset_cache=False, use_ylim=True, clients=[0,1,2,3,4,5], value=\"p99.9\", close_all=True, remove_drops=True, add_shen=True)\n",
    "\n",
    "#     * DARC-110: dynamic with ceiling\n",
    "#     * DARC-118: dynamic with ceiling + no std::sort\n",
    "#     * DARC-119: dynamic with ceiling + only 5us updates\n",
    "#     * DARC-106 : oracle with ceiling\n",
    "\n",
    "#     * DARC-111: dynamic with rounding // & 97 on faster machine // & 125\n",
    "#     * DARC-142: dynamic with rounding + only 5us updates % 10k samples // & 126\n",
    "#     * DARC-103: oracle with rounding // & 94 on faster machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = cache['TPCC']['typed']\n",
    "# print(tmp[tmp.load == 1.05])\n",
    "cache['TPCC']['typed'] = tmp.drop(tmp[tmp.load == 1.1].index)\n",
    "tmp = cache['TPCC']['typed']\n",
    "\n",
    "rn = tmp.run_number.unique()[0]\n",
    "for t in ['Payment', 'OrderStatus', 'NewOrder']:\n",
    "    row = {'policy': 'DYN-RESA', 'load': 1.1, 'type': t, 'run_number': 33, 'mean': 1, 'median': 1, 'p99': 1, 'p99.99': 1e9, 'p99_slowdown': 4, 'p99.9_slowdown': 4, 'p99.9': 1e9, 'offered': workloads['TPCC']['max_load'] * 1.1 / 1000, 'achieved':  workloads['TPCC']['max_load'] * 1.1 / 1000, 'reserved': 13}\n",
    "    tmp.loc[max(tmp.index)+1] = row\n",
    "\n",
    "print(tmp[tmp.load == 1.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cbbb14b218943e79ba622b44bb7d441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[c-PRE-MQ_0.70_TPCC_14.1] Missing 2 client histogram(s)\n"
     ]
    }
   ],
   "source": [
    "distros = ['TPCC']\n",
    "plot_p99s(distros, app='TPCC', reset_cache=False, clients=[0,1,2,3,4,5], use_ylim=True, remove_drops=False, value=\"p99.9\", add_shen=True)\n",
    "\n",
    "\n",
    "#     * DARC-28: Dynamic ceiling without mapping\n",
    "#     * DARC-24 : Oracle ceiling without mapping\n",
    "\n",
    "#     * DARC-29: Dynamic rounding without mapping\n",
    "#     * DARC-25: Oracle rounding without mapping\n",
    "\n",
    "#     * DARC-30: Dynamic ceiling with mapping\n",
    "#     * DARC-31: Oracle ceiling with mapping\n",
    "\n",
    "#     * DARC-33: Dynamic rounding with mapping\n",
    "#     * DARC-32: Oracle rounding with mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0848e83d5c284262bb5aa99ca0b81421",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d-FCFS empty\n",
      "c-FCFS empty\n",
      "ARS-FP empty\n",
      "EDF empty\n",
      "c-PRE-SQ empty\n"
     ]
    }
   ],
   "source": [
    "distros = ['TPCC']\n",
    "plot_p99s(distros, app='TPCC', reset_cache=False, clients=[0,1,2,3,4,5], use_ylim=True, remove_drops=False, value=\"p99.9\", add_shen=True)\n",
    "\n",
    "\n",
    "#     * DARC-28: Dynamic ceiling without mapping\n",
    "#     * DARC-24 : Oracle ceiling without mapping\n",
    "\n",
    "#     * DARC-29: Dynamic rounding without mapping\n",
    "#     * DARC-25: Oracle rounding without mapping\n",
    "\n",
    "#     * DARC-30: Dynamic ceiling with mapping\n",
    "#     * DARC-31: Oracle ceiling with mapping\n",
    "\n",
    "#     * DARC-33: Dynamic rounding with mapping\n",
    "#     * DARC-32: Oracle rounding with mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed6fcaebb8554aab8008b97f47653e0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DISP3] Parsed histograms in 113.221235 seconds\n",
      "[DISP3] Prepared df rows in 0.159024 seconds\n",
      "[DISP3] Created df in 0.011126 seconds\n",
      "d-FCFS empty\n",
      "shen-d-FCFS empty\n",
      "shen-c-FCFS empty\n",
      "ARS-FP empty\n",
      "c-PRE-SQ empty\n",
      "c-PRE-MQ empty\n"
     ]
    }
   ],
   "source": [
    "distros = ['DISP3']\n",
    "plot_p99s(distros, app='MB', reset_cache=True, use_ylim=True, clients=[0,1,2,3,4,5], value=\"p99.9\", remove_drops=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_agg_p99_over_time('DYN-RESA_0.80_sched4_14.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = [\n",
    "'TEST_DYN-RESA_0.50_multi_8.3',\n",
    "]\n",
    "\n",
    "plot_setups_traces(exps, show_ts=False, verbose=False, app=\"MB\", clients=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wcc('WC', reset_cache=False, clients=[0,1,2,3,4,5], value=\"p99.9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wcc('DISP2_WC', reset_cache=False, clients=[0,1,2,3,4,5], value=\"p99.9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# l1 = {\n",
    "#     'policy': 'c-PRE-MQ',\n",
    "#     'load': 0.80,\n",
    "#     'type': 'UNKNOWN',\n",
    "#     'mean': 18,\n",
    "#     'median': 16,\n",
    "#     'p99': 1e9,\n",
    "#     'p99.9': 1e9,\n",
    "#     'p99.99': 1e9,\n",
    "#     'p99_slowdown': 1e9,\n",
    "#     'p99.9_slowdown': 1e9,\n",
    "#     'achieved': 34,\n",
    "#     'offered': 34,\n",
    "# }\n",
    "\n",
    "# l3 = {\n",
    "#     'policy': 'DYN-RESA',\n",
    "#     'load': 1,\n",
    "#     'type': 'SHORT',\n",
    "#     'mean': 18,\n",
    "#     'median': 16,\n",
    "#     'p99': 1e9,\n",
    "#     'p99.9': 1e9,\n",
    "#     'p99.99': 1e9,\n",
    "#     'p99_slowdown': 1e9,\n",
    "#     'p99.9_slowdown': 1e9,\n",
    "#     'achieved': 45,\n",
    "#     'offered': 45,\n",
    "# }\n",
    "# cache['ROCKSDB']['all'] = cache['ROCKSDB']['all'].append(l1, ignore_index=True)\n",
    "# cache['ROCKSDB']['typed'] = cache['ROCKSDB']['typed'].append(l3, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "# l1 = {\n",
    "#     'policy': 'c-PRE-SQ',\n",
    "#     'load': 0.60,\n",
    "#     'type': 'UNKNOWN',\n",
    "#     'mean': 18,\n",
    "#     'median': 16,\n",
    "#     'p99': 60,\n",
    "#     'p99.9': '1e9',\n",
    "#     'p99.99': '1e9',\n",
    "#     'p99_slowdown': 1e9,\n",
    "#     'p99.9_slowdown': 1e9,\n",
    "#     'achieved': 2805,\n",
    "#     'offered': 2805,\n",
    "# }\n",
    "\n",
    "\n",
    "# l3 = {\n",
    "#     'policy': 'DYN-RESA',\n",
    "#     'load': 0.85,\n",
    "#     'type': 'UNKNOWN',\n",
    "#     'mean': 18,\n",
    "#     'median': 16,\n",
    "#     'p99': 60,\n",
    "#     'p99.9': '1e9',\n",
    "#     'p99.99': '1e9',\n",
    "#     'p99_slowdown': 1e9,\n",
    "#     'p99.9_slowdown': 1e9,\n",
    "#     'achieved': 4000,\n",
    "#     'offered': 4000,\n",
    "# }\n",
    "# cache['SBIM2']['all'] = cache['SBIM2']['all'].append(l1, ignore_index=True)\n",
    "# cache['SBIM2']['all'] = cache['SBIM2']['all'].append(l3, ignore_index=True)\n",
    "# cache['SBIM2']['typed'].\n",
    "\n",
    "\n",
    "l1 = {\n",
    "    'policy': 'c-PRE-MQ',\n",
    "    'load': 0.80,\n",
    "    'type': 'UNKNOWN',\n",
    "    'mean': 18,\n",
    "    'median': 16,\n",
    "    'p99': 1e9,\n",
    "    'p99.9': 1e9,\n",
    "    'p99.99': 1e9,\n",
    "    'p99_slowdown': 1e9,\n",
    "    'p99.9_slowdown': 1e9,\n",
    "    'achieved': 220,\n",
    "    'offered': 220,\n",
    "}\n",
    "\n",
    "# l3 = {\n",
    "#     'policy': 'DYN-RESA',\n",
    "#     'load': 0.95,\n",
    "#     'type': 'UNKNOWN',\n",
    "#     'mean': 18,\n",
    "#     'median': 16,\n",
    "#     'p99': 1e9,\n",
    "#     'p99.9': 1e9,\n",
    "#     'p99.99': 1e9,\n",
    "#     'p99_slowdown': 1e9,\n",
    "#     'p99.9_slowdown': 1e9,\n",
    "#     'achieved': 270,\n",
    "#     'offered': 270,\n",
    "# }\n",
    "cache['DISP2']['all'] = cache['DISP2']['all'].append(l1, ignore_index=True)\n",
    "# cache['DISP2']['all'] = cache['DISP2']['all'].append(l3, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "exp = 'w8_0.50_SJF.75'\n",
    "df = read_client_tp(exp)\n",
    "df.N *= 1000\n",
    "df.TIME -= min(df.TIME)\n",
    "fig, axes = plt.subplots(len(df.W_ID.unique()), 1, squeeze=False)\n",
    "print('{} overall average throughput: {}'.format(exp, int(df.groupby(['W_ID','TYPE']).N.mean().sum())))\n",
    "for i, w in enumerate(df.W_ID.unique()):\n",
    "    w_df = df[df.W_ID == w]\n",
    "    print('worker {} overall average throughput: {}'.format(w, int(w_df.groupby(['W_ID', 'TYPE']).N.mean().sum())))\n",
    "    print('worker {} average {} throughput: {}, average {} throughput: {}'.format(\n",
    "        w,\n",
    "        'PAGE', int(w_df[w_df.TYPE == 'PAGE'].groupby('W_ID').N.mean().sum()),\n",
    "        'REGEX', int(w_df[w_df.TYPE == 'REGEX'].groupby('W_ID').N.mean().sum()),\n",
    "    ))\n",
    "    sns.lineplot(x='TIME', y='N', data=w_df, ax=axes[i][0], ci=None)\n",
    "    axes[i][0].set_ylim(ymin=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
